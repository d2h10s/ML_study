{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    " # MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software. #\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit fashion mnist 데이터 셋의 일부를 약간 변형하여 만든 과제를 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow keras dataset에서 가져온 데이타셋.\n",
    "train_image = np.load('hw_train_image.npy')\n",
    "train_label = np.load('hw_train_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-humanity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(train_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정답 : %d\" %train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = {}\n",
    "class_name[0] = 'sandal'\n",
    "class_name[1] = 'sneaker'\n",
    "class_name[2] = 'ankle boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 셔플\n",
    "index = np.array(range(len(train_image)))\n",
    "np.random.shuffle(index)\n",
    "train_image = train_image[index]\n",
    "train_label = train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 : 필요하다면 원하는대로 수정할 것. (단 openCV등 패키지는 사용불가하고, 넘파이만 이용해서 전처리할 것.)\n",
    "train_image = (train_image -[128]) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터와 검증데이터 분리 \n",
    "sp = int(1e4)  # 원하는 숫자로 변경 가능.\n",
    "train_x = train_image[:sp]\n",
    "train_y = train_label[:sp].astype(np.int32)\n",
    "valid_x = train_image[sp:]\n",
    "valid_y = train_label[sp:].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = train_x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토치 텐서로 변환\n",
    "train_x = torch.FloatTensor(train_x).view(-1,1, 28,28)\n",
    "train_y = torch.LongTensor(train_y)\n",
    "valid_x = torch.FloatTensor(valid_x).view(-1,1,28,28)\n",
    "valid_y = torch.LongTensor(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        #input (num_batch, channel=1, 28, 28)\n",
    "        #생각한 신경망 모델로 변환할 것. (Conv2d, Linear 조합 이용.)\n",
    "        self.conv1 = nn.Conv2d(1, 30, kernel_size = 28, stride=1, padding=0)  \n",
    "        self.fc    = nn.Linear(30, 3) \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x): #구현한 신경망 모델에 따라 적절히 변형할 것\n",
    "        x = F.relu(self.conv1(x)) \n",
    "        x = x.view(-1, 30)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, image): #test image는 넘파이 (28,28) 형상 2d 배열임. 테스트 이미지 1장을 입력했을 때 결과가 출력되도록 할 것.\n",
    "        image = (image -[128])/128\n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = image.view(-1,1, 28,28)\n",
    "        out   = self.forward(image).view(-1)\n",
    "        return out.argmax().item()\n",
    "    \n",
    "    def accuracy(self, input_data, target_data):\n",
    "        predict = self.forward(input_data).argmax(axis=1)\n",
    "        correct_cnt = sum(predict==target_data)\n",
    "        return correct_cnt.item()/len(target_data)\n",
    "    \n",
    "    def save(self, name):\n",
    "        torch.save(self.state_dict(), name + '.pt')\n",
    "        print('Models saved successfully')\n",
    "    \n",
    "    def load(self, name):\n",
    "        self.load_state_dict(torch.load(name + '.pt'))\n",
    "        print ('Models loaded succesfully')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    \n",
    "    def __init__(self, net, lr, figname, train_x, train_y, valid_x, valid_y):\n",
    "        \n",
    "        self.net = net\n",
    "        self.lrate = lr\n",
    "        self.name = figname\n",
    "        self.train_x, self.train_y = train_x, train_y\n",
    "        self.valid_x, self.valid_y = valid_x, valid_y\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lrate)\n",
    "        self.loss_layer    = nn.CrossEntropyLoss()\n",
    "        self.train_loss_history = [] \n",
    "        self.valid_acc_history = [] \n",
    "    \n",
    "    def plot(self, train_loss, valid_acc):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.subplot(121)\n",
    "        plt.title('train loss')\n",
    "        plt.plot(train_loss, 'k-')\n",
    "        plt.subplot(122)\n",
    "        plt.title('valid acc')\n",
    "        plt.plot(valid_acc)\n",
    "        plt.savefig(self.name +'.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, epoch=10):\n",
    "        \n",
    "        for j in range(epoch):\n",
    "            \n",
    "            train_loss = 0\n",
    "            idx = np.array(range(sp))\n",
    "            np.random.shuffle(idx)\n",
    "            train_x = self.train_x[idx]\n",
    "            train_y = self.train_y[idx]\n",
    "            batch_size = 500 # 필요한 경우 변경\n",
    "            for k in range(len(train_x)//batch_size): #필요한 경우 레인지 내 변수 변경\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_layer(self.net.forward(train_x[batch_size*k:batch_size*(k+1)]), train_y[batch_size*k:batch_size*(k+1)])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                \n",
    "            self.train_loss_history.append(train_loss)\n",
    "            self.valid_acc_history.append(self.net.accuracy(valid_x, valid_y))\n",
    "            \n",
    "            self.plot(self.train_loss_history, self.valid_acc_history)\n",
    "            if np.argmax(self.valid_acc_history) == j:\n",
    "                print(\"%d-th epoch에서 진척이 있었음.\" %(j+1))\n",
    "                savename = 'cnn' + self.name\n",
    "                self.net.save(savename)\n",
    "            else:\n",
    "                print(\"%d-th epoch에서는 진척 없음.\" %(j+1))\n",
    "            print(\"현재 검증 데이터의 분류 성공율 최댓값은 %.3f%%\" %(100*np.max(self.valid_acc_history)))\n",
    "        print(\"훈련 종료.\")\n",
    "        print(\"%d번째 epoch에서 검증 정답율 최대\" %(np.argmax(self.valid_acc_history)+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 학습율로 변경\n",
    "tt = trainer(cnn, 1e-3, 'lr1e-3', train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 회수로 변경\n",
    "tt.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출한 세이브파일을 로드할 수 있도록 파일 네임을 입력해서 제출\n",
    "cnn.load('cnnlr1e-3') \n",
    "cnn.accuracy(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 부분을 채점을 위한 부분임. \n",
    "# 아래 부분은 변경불가!\n",
    "#이 부분이 실행되지 않으면 채점불가하니, 아래 부분이 실행될 수 있도록 과제를 제출 할 것. \n",
    "# test data는 개수만 다를 뿐 초기형태는 훈련데이터와 동일한 (28,28) 2d 넘파이 배열임.\n",
    "test_image = np.load('hw_test_image.npy')\n",
    "test_label = np.load('hw_test_label.npy')\n",
    "ctr = 0\n",
    "for i, img in enumerate(test_image):\n",
    "    guess = cnn.predict(img)\n",
    "    if guess == test_label[i]:\n",
    "        ctr +=1\n",
    "print(\"테스트 데이터 분류 성공율 : %.2f%%\" %(100*ctr/len(test_label)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
