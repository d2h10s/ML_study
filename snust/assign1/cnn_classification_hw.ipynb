{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thousand-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monetary-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    " # MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software. #\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innocent-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit fashion mnist 데이터 셋의 일부를 약간 변형하여 만든 과제를 위한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cathedral-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow keras dataset에서 가져온 데이타셋.\n",
    "train_image = np.load('hw_train_image.npy')\n",
    "train_label = np.load('hw_train_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boxed-humanity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18000, 28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legislative-textbook",
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 144x144 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"141.655915pt\" version=\"1.1\" viewBox=\"0 0 142.845 141.655915\" width=\"142.845pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-08T21:25:59.901259</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 141.655915 \r\nL 142.845 141.655915 \r\nL 142.845 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 117.77779 \r\nL 135.645 117.77779 \r\nL 135.645 9.05779 \r\nL 26.925 9.05779 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p6d08f75fce)\">\r\n    <image height=\"109\" id=\"image9ae2cb8905\" transform=\"scale(1 -1)translate(0 -109)\" width=\"109\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-8.77779\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mebb6c8f929\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.866429\" xlink:href=\"#mebb6c8f929\" y=\"117.77779\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(25.685179 132.376228)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"67.695\" xlink:href=\"#mebb6c8f929\" y=\"117.77779\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(61.3325 132.376228)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.523571\" xlink:href=\"#mebb6c8f929\" y=\"117.77779\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(100.161071 132.376228)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_4\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"med64ddf118\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med64ddf118\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med64ddf118\" y=\"49.82779\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 53.627009)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med64ddf118\" y=\"88.656362\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 92.45558)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 117.77779 \r\nL 26.925 9.05779 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 135.645 117.77779 \r\nL 135.645 9.05779 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 117.77779 \r\nL 135.645 117.77779 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 9.05779 \r\nL 135.645 9.05779 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p6d08f75fce\">\r\n   <rect height=\"108.72\" width=\"108.72\" x=\"26.925\" y=\"9.05779\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(train_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polished-accuracy",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "정답 : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"정답 : %d\" %train_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "copyrighted-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = {}\n",
    "class_name[0] = 'sandal'\n",
    "class_name[1] = 'sneaker'\n",
    "class_name[2] = 'ankle boot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "introductory-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 셔플\n",
    "index = np.array(range(len(train_image)))\n",
    "np.random.shuffle(index)\n",
    "train_image = train_image[index]\n",
    "train_label = train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "motivated-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 : 필요하다면 원하는대로 수정할 것. (단 openCV등 패키지는 사용불가하고, 넘파이만 이용해서 전처리할 것.)\n",
    "train_image = (train_image -[128]) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pursuant-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터와 검증데이터 분리 \n",
    "sp = int(1e4)  # 원하는 숫자로 변경 가능.\n",
    "train_x = train_image[:sp]\n",
    "train_y = train_label[:sp].astype(np.int32)\n",
    "valid_x = train_image[sp:]\n",
    "valid_y = train_label[sp:].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = train_x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stuffed-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토치 텐서로 변환\n",
    "train_x = torch.FloatTensor(train_x).view(-1,1, 28,28)\n",
    "train_y = torch.LongTensor(train_y)\n",
    "valid_x = torch.FloatTensor(valid_x).view(-1,1,28,28)\n",
    "valid_y = torch.LongTensor(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(torch.nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        \n",
    "        #input (num_batch, channel=1, 28, 28)\n",
    "        self.input_size = 28\n",
    "        # [batch, 1, 28, 28]\n",
    "        #생각한 신경망 모델로 변환할 것. (Conv2d, Linear 조합 이용.)\n",
    "\n",
    "        self.conv1  = nn.Conv2d(1, 16, kernel_size = 3, stride=1, padding=1)\n",
    "        self.conv2  = nn.Conv2d(16, 32, kernel_size = 3, stride=1, padding=1)\n",
    "        self.conv3  = nn.Conv2d(32, 64, kernel_size = 3, stride=1, padding=1)\n",
    "        self.conv4  = nn.Conv2d(64, 128, kernel_size = 3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv1_size = ((self.input_size-self.conv1.kernel_size[0]+2*self.conv1.padding[0])//self.conv1.stride[0]+1)//2\n",
    "        # [batch, 32, (28-3)/1+1, 26]\n",
    "        print(self.conv1_size)\n",
    "\n",
    "        self.conv2_size = ((self.conv1_size - self.conv2.kernel_size[0]+2*self.conv2.padding[0])//self.conv2.stride[0]+1)//2\n",
    "        # [batch, 64, (26-3)/1+1, 25]\n",
    "        print(self.conv2_size)\n",
    "\n",
    "        self.conv3_size = ((self.conv2_size - self.conv3.kernel_size[0]+2*self.conv3.padding[0])//self.conv3.stride[0]+1)//2\n",
    "        # [batch, 128, (25-2+2)/1+1, 26]\n",
    "        print(self.conv3_size)\n",
    "\n",
    "        self.conv4_size = ((self.conv3_size - self.conv4.kernel_size[0]+2*self.conv4.padding[0])//self.conv4.stride[0]+1)//2\n",
    "        # [batch, 128, (25-2+2)/1+1, 26]\n",
    "        print(self.conv3_size)\n",
    "\n",
    "        self.fc     = nn.Linear(self.conv4.out_channels * self.conv4_size**2, 3)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x): #구현한 신경망 모델에 따라 적절히 변형할 것\n",
    "        self.batch_size = x.shape[0]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self, image): #test image는 넘파이 (28,28) 형상 2d 배열임. 테스트 이미지 1장을 입력했을 때 결과가 출력되도록 할 것.\n",
    "        image = (image -[128])/128\n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = image.view(-1,1, 28,28)\n",
    "        out   = self.forward(image).view(-1)\n",
    "        return out.argmax().item()\n",
    "    \n",
    "    def accuracy(self, input_data, target_data):\n",
    "        predict = self.forward(input_data).argmax(axis=1)\n",
    "        correct_cnt = sum(predict==target_data)\n",
    "        return correct_cnt.item()/len(target_data)\n",
    "    \n",
    "    def save(self, name):\n",
    "        torch.save(self.state_dict(), name + '.pt')\n",
    "        print('Models saved successfully')\n",
    "    \n",
    "    def load(self, name):\n",
    "        self.load_state_dict(torch.load(name + '.pt'))\n",
    "        print ('Models loaded succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    \n",
    "    def __init__(self, net, lr, figname, train_x, train_y, valid_x, valid_y):\n",
    "        \n",
    "        self.net = net\n",
    "        self.lrate = lr\n",
    "        self.name = figname\n",
    "        self.train_x, self.train_y = train_x, train_y\n",
    "        self.valid_x, self.valid_y = valid_x, valid_y\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lrate)\n",
    "        self.loss_layer    = nn.CrossEntropyLoss()\n",
    "        self.train_loss_history = [] \n",
    "        self.valid_acc_history = [] \n",
    "    \n",
    "    def plot(self, train_loss, valid_acc):\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.subplot(121)\n",
    "        plt.title('train loss')\n",
    "        plt.plot(train_loss, 'k-')\n",
    "        plt.subplot(122)\n",
    "        plt.title('valid acc')\n",
    "        plt.plot(valid_acc)\n",
    "        plt.savefig(self.name +'.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, epoch=10):\n",
    "        \n",
    "        for j in range(epoch):\n",
    "            \n",
    "            train_loss = 0\n",
    "            idx = np.array(range(sp))\n",
    "            np.random.shuffle(idx)\n",
    "            train_x = self.train_x[idx]\n",
    "            train_y = self.train_y[idx]\n",
    "            batch_size = 500 # 필요한 경우 변경\n",
    "            for k in range(len(train_x)//batch_size): #필요한 경우 레인지 내 변수 변경\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_layer(self.net.forward(train_x[batch_size*k:batch_size*(k+1)]), train_y[batch_size*k:batch_size*(k+1)])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                \n",
    "            self.train_loss_history.append(train_loss)\n",
    "            self.valid_acc_history.append(self.net.accuracy(valid_x, valid_y))\n",
    "            \n",
    "            self.plot(self.train_loss_history, self.valid_acc_history)\n",
    "            if np.argmax(self.valid_acc_history) == j:\n",
    "                print(\"%d-th epoch에서 진척이 있었음.\" %(j+1))\n",
    "                savename = 'cnn' + self.name\n",
    "                self.net.save(savename)\n",
    "            else:\n",
    "                print(\"%d-th epoch에서는 진척 없음.\" %(j+1))\n",
    "            print(\"현재 검증 데이터의 분류 성공율 최댓값은 %.3f%%\" %(100*np.max(self.valid_acc_history)))\n",
    "        print(\"훈련 종료.\")\n",
    "        print(\"%d번째 epoch에서 검증 정답율 최대\" %(np.argmax(self.valid_acc_history)+1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 학습율로 변경\n",
    "tt = trainer(cnn, 1e-3, 'lr1e-3', train_x, train_y, valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 회수로 변경\n",
    "tt.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.accuracy(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출한 세이브파일을 로드할 수 있도록 파일 네임을 입력해서 제출\n",
    "cnn.load('cnnlr1e-3') \n",
    "cnn.accuracy(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 부분을 채점을 위한 부분임. \n",
    "# 아래 부분은 변경불가!\n",
    "#이 부분이 실행되지 않으면 채점불가하니, 아래 부분이 실행될 수 있도록 과제를 제출 할 것. \n",
    "# test data는 개수만 다를 뿐 초기형태는 훈련데이터와 동일한 (28,28) 2d 넘파이 배열임.\n",
    "test_image = np.load('hw_test_image.npy')\n",
    "test_label = np.load('hw_test_label.npy')\n",
    "ctr = 0\n",
    "for i, img in enumerate(test_image):\n",
    "    guess = cnn.predict(img)\n",
    "    if guess == test_label[i]:\n",
    "        ctr +=1\n",
    "print(\"테스트 데이터 분류 성공율 : %.2f%%\" %(100*ctr/len(test_label)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd024b81c45c1dc1e69ab378e03e1fcac7296434f7dbf10e15b6bd5c21a8ac878c1",
   "display_name": "Python 3.8.8 64-bit ('ML38': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}